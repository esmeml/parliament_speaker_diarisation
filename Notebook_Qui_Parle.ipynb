{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGNymWdHA7LBAgW8NsrFOX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpxI9LWuWR2m","executionInfo":{"status":"ok","timestamp":1768207229629,"user_tz":-60,"elapsed":1807,"user":{"displayName":"Petit Chevalier_Bleu","userId":"13076775108994109078"}},"outputId":"bd98a309-496c-4917-c62a-b6749f648a0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'parliament_speaker_diarisation'...\n","remote: Enumerating objects: 14, done.\u001b[K\n","remote: Counting objects: 100% (14/14), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 14 (delta 2), reused 6 (delta 1), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (14/14), 1.24 MiB | 5.69 MiB/s, done.\n","Resolving deltas: 100% (2/2), done.\n","Dépôt parliament_speaker_diarisation cloné avec succès !\n","/content/parliament_speaker_diarisation\n"]}],"source":["from google.colab import userdata\n","import os\n","\n","# 1. Récupération des secrets\n","try:\n","    token = userdata.get('GITHUB_TOKEN')\n","except ImportError:\n","    print(\"Erreur: Assurez-vous d'avoir ajouté le secret GITHUB_TOKEN dans la barre latérale.\")\n","    token = input(\"Entrez votre token manuellement: \")\n","\n","# 2. Configuration des variables\n","username = \"Thorbjornen\"\n","repo_owner = \"esmeml\" # Le compte qui possède le repo\n","repo_name = \"parliament_speaker_diarisation\"\n","user_email = \"niels.groeninck4@gmail.com\"\n","\n","# 3. Configuration de l'identité Git (nécessaire pour commit)\n","!git config --global user.email \"{user_email}\"\n","!git config --global user.name \"{username}\"\n","\n","# 4. Clonage du dépôt avec authentification\n","# La syntaxe est : https://<token>@github.com/<owner>/<repo>.git\n","clone_url = f\"https://{token}@github.com/{repo_owner}/{repo_name}.git\"\n","\n","# On clone uniquement si le dossier n'existe pas déjà\n","if not os.path.exists(repo_name):\n","    !git clone {clone_url}\n","    print(f\"Dépôt {repo_name} cloné avec succès !\")\n","else:\n","    print(f\"Le dossier {repo_name} existe déjà.\")\n","\n","# 5. Se déplacer dans le dossier du dépôt\n","%cd {repo_name}"]},{"cell_type":"code","source":["# Installation des librairies nécessaires pour le traitement audio et le XML\n","!pip install librosa soundfile lxml tensorflow\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import librosa\n","import soundfile as sf\n","import xml.etree.ElementTree as ET\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from google.colab import drive\n","\n","# 1. Connexion au Google Drive\n","drive.mount('/content/drive')\n","print(\"Google Drive connecté.\")"],"metadata":{"id":"ueS_2IPzYNK3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["AUDIO_FILE_NAME = '4_decembre.wav'\n","XML_FILE_NAME = '4_decembre.xml'\n","\n","# Chemins (Racine du Drive)\n","BASE_DIR = '/content/drive/MyDrive'\n","AUDIO_PATH = os.path.join(BASE_DIR, AUDIO_FILE_NAME)\n","XML_PATH = os.path.join(BASE_DIR, XML_FILE_NAME)\n","\n","# Dossier où seront créés les petits segments audio\n","OUTPUT_DATASET_DIR = os.path.join(BASE_DIR, 'Dataset_Assemblee_CTC')\n","CSV_MANIFEST_PATH = os.path.join(OUTPUT_DATASET_DIR, 'metadata.csv')\n","\n","# Paramètres Audio pour CTC\n","TARGET_SR = 16000  # Standard pour la reconnaissance vocale (16kHz)\n","\n","# Création du dossier de sortie s'il n'existe pas\n","os.makedirs(OUTPUT_DATASET_DIR, exist_ok=True)\n","\n","print(f\"Dossier de travail : {OUTPUT_DATASET_DIR}\")\n","if not os.path.exists(AUDIO_PATH):\n","    print(f\"ERREUR : Le fichier audio '{AUDIO_FILE_NAME}' est introuvable à la racine du Drive !\")\n","else:\n","    print(f\"Fichier audio détecté : {AUDIO_PATH}\")"],"metadata":{"id":"hBWt5Z9gYS0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xml.etree.ElementTree as ET\n","import json\n","import os\n","import re\n","\n","# Config\n","XML_FILE = '/content/drive/MyDrive/4_decembre.xml'\n","JSON_OUTPUT = '/content/drive/MyDrive/segments_clean.json'\n","\n","def xml_to_json_segments(xml_path):\n","    print(f\"Lecture du fichier : {xml_path}\")\n","\n","    with open(xml_path, 'r', encoding='utf-8') as f:\n","        content = f.read()\n","\n","    # On retire les namespaces\n","    content = re.sub(r' xmlns=\"[^\"]+\"', '', content)\n","\n","    root = ET.fromstring(content)\n","\n","    raw_segments = []\n","\n","    # On utilise .iter() pour aller chercher l'info partout\n","    all_paras = list(root.iter('paragraphe'))\n","    print(f\"Nombre de paragraphes trouvés : {len(all_paras)}\")\n","\n","    for para in all_paras:\n","        texte_node = para.find('texte')\n","\n","        if texte_node is not None and 'stime' in texte_node.attrib:\n","            try:\n","                start_time = float(texte_node.attrib['stime'])\n","\n","                # 1. Extraction brute de tout le texte (y compris dans les balises enfants)\n","                raw_text = \"\".join(texte_node.itertext())\n","\n","                # 2. Enlever les \\n\n","                clean_text = \" \".join(raw_text.split())\n","\n","                # 3. Chercher le locuteur\n","                speaker = \"Inconnu\"\n","                orateurs = para.find('orateurs')\n","                if orateurs is not None:\n","                    orateur = orateurs.find('orateur')\n","                    if orateur is not None:\n","                        nom = orateur.find('nom')\n","                        if nom is not None:\n","                            speaker = nom.text\n","\n","                if clean_text:\n","                    raw_segments.append({\n","                        'start': start_time,\n","                        'speaker': speaker,\n","                        'text': clean_text\n","                    })\n","\n","            except ValueError:\n","                continue\n","\n","    # Tri et calcul des durées\n","    raw_segments.sort(key=lambda x: x['start'])\n","\n","    final_dataset = []\n","\n","    for i in range(len(raw_segments) - 1):\n","        curr = raw_segments[i]\n","        nxt = raw_segments[i+1]\n","\n","        duration = nxt['start'] - curr['start']\n","\n","        # Filtres de qualité\n","        # On garde si c'est raisonnable (entre 0.5s et 60s)\n","        # On augmente un peu la tolérance car les applaudissements peuvent être longs\n","        if 0.5 <= duration <= 60.0:\n","            curr['end'] = nxt['start']\n","            curr['duration'] = round(duration, 3)\n","            final_dataset.append(curr)\n","\n","    # Sauvegarde\n","    with open(JSON_OUTPUT, 'w', encoding='utf-8') as f:\n","        json.dump(final_dataset, f, indent=4, ensure_ascii=False)\n","\n","    print(f\"Succès ! {len(final_dataset)} segments sauvegardés dans :\")\n","    print(f\"   -> {JSON_OUTPUT}\")\n","\n","    # Vérification visuelle\n","    if len(final_dataset) > 0:\n","        print(\"\\nExemple corrigé (regardez le champ 'text') :\")\n","        # On cherche un segment qui contient une parenthèse pour vérifier\n","        for seg in final_dataset:\n","            if '(' in seg['text']:\n","                print(json.dumps(seg, indent=4, ensure_ascii=False))\n","                break\n","\n","# Lancer la correction\n","xml_to_json_segments(XML_FILE)"],"metadata":{"id":"q2HnkqmvYeb1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import librosa\n","import soundfile as sf\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# Config\n","# Le fichier JSON créé précédemment\n","JSON_FILE = '/content/drive/MyDrive/segments_clean.json'\n","# Fichier audio source\n","AUDIO_FILE = '/content/drive/MyDrive/4_decembre.wav'\n","# Le dossier pour petits fichiers wav (segments)\n","OUTPUT_DIR = '/content/drive/MyDrive/Dataset_Assemblee_CTC'\n","\n","# Création du dossier si nécessaire\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","def create_audio_dataset_from_json():\n","    \"\"\"\n","    Lit le JSON, charge l'audio, découpe et sauvegarde les segments.\n","    Génère aussi le CSV final pour l'entraînement.\n","    \"\"\"\n","\n","    # 1. Vérification du fichier JSON\n","    if not os.path.exists(JSON_FILE):\n","        print(f\"ERREUR : Le fichier JSON {JSON_FILE} n'existe pas !\")\n","        print(\"   -> Avez-vous bien lancé la fonction xml_to_json_segments() avant ?\")\n","        return\n","\n","    # 2. Chargement des segments depuis le JSON\n","    print(f\"Chargement du JSON : {JSON_FILE}\")\n","    with open(JSON_FILE, 'r', encoding='utf-8') as f:\n","        segments = json.load(f)\n","    print(f\"{len(segments)} segments chargés à traiter.\")\n","\n","    # 3. Chargement de l'audio complet\n","    print(f\"Chargement du fichier audio complet en mémoire (16kHz)... Cela peut prendre 1 à 2 minutes.\")\n","    # On force le chargement en 16000 Hz car c'est le standard pour CTC/ASR\n","    try:\n","        y, sr = librosa.load(AUDIO_FILE, sr=16000)\n","        print(f\"Audio chargé ! Durée totale : {len(y)/sr:.2f} secondes.\")\n","    except Exception as e:\n","        print(f\"ERREUR lors du chargement de l'audio : {e}\")\n","        return\n","\n","    csv_data = []\n","\n","    print(\"Découpage et sauvegarde des segments audio...\")\n","    # tqdm pour voir la progression\n","    for i, seg in enumerate(tqdm(segments)):\n","        try:\n","            # Calcul des index de début et fin\n","            start_sample = int(seg['start'] * sr)\n","            end_sample = int(seg['end'] * sr)\n","\n","            # Extraction du bout d'audio\n","            # Vérification pour ne pas dépasser la taille du fichier\n","            if end_sample > len(y):\n","                end_sample = len(y)\n","\n","            clip = y[start_sample:end_sample]\n","\n","            # Sauvegarde du petit fichier wav\n","            filename = f\"segment_{i:05d}.wav\"\n","            path = os.path.join(OUTPUT_DIR, filename)\n","            sf.write(path, clip, sr)\n","\n","            # On ajoute les infos pour le CSV\n","            csv_data.append({\n","                \"filename\": filename,\n","                \"text\": seg['text'],\n","                \"speaker\": seg['speaker'],\n","                \"duration\": seg['duration']\n","            })\n","\n","        except Exception as e:\n","            print(f\"Erreur sur le segment {i} : {e}\")\n","            continue\n","\n","    # 4. Création du fichier Metadata (CSV)\n","    df = pd.DataFrame(csv_data)\n","    csv_path = os.path.join(OUTPUT_DIR, 'metadata.csv')\n","    df.to_csv(csv_path, index=False)\n","\n","    print(f\"\\nTRAITEMENT TERMINÉ\")\n","    print(f\"   -> {len(df)} fichiers audio créés dans : {OUTPUT_DATASET_DIR}\")\n","    print(f\"   -> Fichier index (CSV) créé : {csv_path}\")\n","    print(\"\\n   Aperçu du CSV :\")\n","    print(df.head())\n","\n","# Lancement\n","create_audio_dataset_from_json()"],"metadata":{"id":"tQ2O3DBvZAwd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dans la cellule précédente on a eu un problème de décallage"],"metadata":{"id":"8x5gOZyIZB-q"}},{"cell_type":"markdown","source":["Connexion au drive"],"metadata":{"id":"R7AzziTqaBg9"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","# 1. Connexion au Google Drive\n","drive.mount('/content/drive')\n","print(\"Google Drive connecté.\")"],"metadata":{"id":"g2nWpb-VZxju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Whisper"],"metadata":{"id":"E4IADGmTbsZB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import os\n","import soundfile as sf\n","import librosa\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Config\n","# Fichiers\n","JSON_FILE = '/content/drive/MyDrive/segments_perfect.json'\n","AUDIO_FILE = '/content/drive/MyDrive/4_decembre.wav'\n","\n","# Dossier de sortie\n","OUTPUT_DIR = '/content/drive/MyDrive/Dataset_Assemblee_Final'\n","WAVS_DIR = os.path.join(OUTPUT_DIR, 'wavs')\n","\n","# Paramètres audio cibles pour l'entraînement\n","TARGET_SR = 16000 # 16kHz est le standard\n","Target_CHANNELS = 1 # Mono\n","\n","# Création de l'arborescence\n","os.makedirs(WAVS_DIR, exist_ok=True)\n","\n","def cut_and_save_dataset():\n","    # 1. Vérifications\n","    if not os.path.exists(JSON_FILE):\n","        print(f\"ERREUR : Le JSON {JSON_FILE} n'existe pas.\")\n","        return\n","\n","    print(f\"Lecture du JSON : {JSON_FILE}\")\n","    with open(JSON_FILE, 'r', encoding='utf-8') as f:\n","        segments = json.load(f)\n","    print(f\"{len(segments)} segments à traiter.\")\n","\n","    # 2. Analyse du fichier audio source\n","    print(\"Analyse du fichier audio source...\")\n","    try:\n","        info = sf.info(AUDIO_FILE)\n","        native_sr = info.samplerate\n","        print(f\"   -> Source : {info.duration/3600:.2f} heures @ {native_sr}Hz\")\n","    except Exception as e:\n","        print(f\"Erreur lecture audio : {e}\")\n","        return\n","\n","    csv_data = []\n","\n","    print(\"Découpage, Rééchantillonnage (16k) et Sauvegarde...\")\n","\n","    # Barre de progression\n","    for i, seg in enumerate(tqdm(segments)):\n","        try:\n","            # Calcul des bornes\n","            start_sec = seg['start']\n","            end_sec = seg['end']\n","            duration = end_sec - start_sec\n","\n","            # Sécurité : on ignore les segments vides ou aberrants\n","            if duration < 0.1: continue\n","\n","            # Conversion en frames (échantillons) pour soundfile\n","            start_frame = int(start_sec * native_sr)\n","            frames_to_read = int(duration * native_sr)\n","\n","            # Lecture stream\n","            # On lit seulement le petit morceau nécessaire\n","            audio_clip, _ = sf.read(AUDIO_FILE, start=start_frame, frames=frames_to_read, always_2d=True)\n","\n","            # Traitement audio\n","            # 1. Conversion Stéréo -> Mono (Moyenne des canaux)\n","            if audio_clip.shape[1] > 1:\n","                audio_clip = np.mean(audio_clip, axis=1)\n","            else:\n","                audio_clip = audio_clip.flatten()\n","\n","            # 2. Rééchantillonnage vers 16kHz (si nécessaire)\n","            if native_sr != TARGET_SR:\n","                # librosa.resample est efficace sur des petits clips\n","                audio_clip = librosa.resample(audio_clip, orig_sr=native_sr, target_sr=TARGET_SR)\n","\n","            # Sauvegarde\n","            filename = f\"segment_{i:05d}.wav\"\n","            file_path = os.path.join(WAVS_DIR, filename)\n","\n","            # On écrit le fichier propre (16k, mono)\n","            sf.write(file_path, audio_clip, TARGET_SR)\n","\n","            # Metadata\n","            # On ajoute les infos pour le CSV final\n","            csv_data.append({\n","                \"filename\": filename,          # Nom du fichier (relatif)\n","                \"text\": seg['text'],           # Le texte de Whisper\n","                \"speaker\": seg['speaker'],     # L'orateur du XML\n","                \"duration\": round(len(audio_clip)/TARGET_SR, 2) # Durée réelle\n","            })\n","\n","        except Exception as e:\n","            print(f\"Erreur sur le segment {i} : {e}\")\n","            continue\n","\n","    # 3. Création du fichier Index (CSV)\n","    df = pd.DataFrame(csv_data)\n","    csv_path = os.path.join(OUTPUT_DIR, 'metadata.csv')\n","    df.to_csv(csv_path, index=False)\n","\n","    print(f\"\\nDATASET FINAL TERMINÉ !\")\n","    print(f\"Dossier : {OUTPUT_DIR}\")\n","    print(f\"CSV Index : {csv_path}\")\n","    print(f\"Nombre d'exemples : {len(df)}\")\n","    print(\"\\nAperçu des données :\")\n","    print(df.head())\n","\n","# Lancement\n","cut_and_save_dataset()"],"metadata":{"id":"wO196-I7aG5o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Envoie sur le repo"],"metadata":{"id":"C1ggJrxmdkSr"}},{"cell_type":"code","source":["from google.colab import drive\n","import shutil\n","import os\n","\n","# accès au drive\n","drive.mount('/content/drive')\n","\n","nom_du_notebook = \"Notebook_Qui_Parle.ipynb\"\n","\n","chemin_source = f\"/content/drive/My Drive/Colab Notebooks/{nom_du_notebook}\"\n","\n","# Nom du dossier Git (celui cloné précédemment)\n","nom_dossier_git = \"esmeml/parliament_speaker_diarisation\"\n","# -------------------------------\n","\n","# 2. Vérification que le fichier source existe\n","if not os.path.exists(chemin_source):\n","    print(f\"ERREUR : Le fichier n'a pas été trouvé à l'endroit : {chemin_source}\")\n","    print(\"Vérifiez le nom du fichier ou s'il est dans un sous-dossier de votre Drive.\")\n","else:\n","    # 3. Copie du notebook vers le dossier Git\n","    destination = f\"/content/{nom_dossier_git}/{nom_du_notebook}\"\n","    shutil.copy(chemin_source, destination)\n","    print(f\"Succès : Le notebook a été copié dans le dossier Git !\")\n","\n","    # 4. Envoi vers GitHub\n","    # Changement du repertoire de travail\n","    os.chdir(f\"/content/{nom_dossier_git}\")\n","\n","    print(\"Envoi vers GitHub en cours...\")\n","    !git add \"{nom_du_notebook}\"  # On ajoute spécifiquement le notebook\n","    !git commit -m \"Mise à jour du notebook de déploiement\"\n","    !git push origin main # Ou 'master' selon votre branche\n","\n","    print(\"Terminé ! Le notebook est maintenant sur le repo.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"VPE8GpEDdjtQ","executionInfo":{"status":"error","timestamp":1768209130212,"user_tz":-60,"elapsed":23739,"user":{"displayName":"Petit Chevalier_Bleu","userId":"13076775108994109078"}},"outputId":"8c8a00e2-521b-48e1-c94c-6b474ee6136f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/esmeml/parliament_speaker_diarisation/Notebook_Qui_Parle.ipynb'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-761494072.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# 3. Copie du notebook vers le dossier Git\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/{nom_dossier_git}/{nom_du_notebook}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchemin_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Succès : Le notebook a été copié dans le dossier Git !\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \u001b[0;31m# macOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/esmeml/parliament_speaker_diarisation/Notebook_Qui_Parle.ipynb'"]}]}]}